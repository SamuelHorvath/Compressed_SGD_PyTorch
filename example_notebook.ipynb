{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example notebook\n",
    "\n",
    "This notebook serves as an example on how to run and replicate experiments from our code base\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "from optim.train import tune_step_size, run_tuned_exp\n",
    "from optim.models import MNISTNet, MNISTLogReg, resnet18, vgg11\n",
    "\n",
    "from optim.utils import save_exp, load_exp, read_all_runs, create_exp\n",
    "from utils.plotting import plot\n",
    "\n",
    "from quant.quant import c_nat, random_dithering_wrap, rand_spars_wrap, \\\n",
    "    top_k_wrap, grad_spars_wrap, biased_unbiased_wrap, combine_two_wrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'cifar10' # datasets, current options: 'mnist', 'cifar10', 'cifar100'\n",
    "model = 'resnet18' # for saving purposes\n",
    "net = resnet18  # for the list of all models, see optim/models.py\n",
    "criterion = nn.CrossEntropyLoss()  # loss, which is considered\n",
    "epochs = 50  # number of epochs \n",
    "n_workers = 8  # number of workers\n",
    "batch_size = 32  # local batch size on each worker\n",
    "seed = 40  # fixed seed, which allows experiment replication\n",
    "lrs = np.array([0.1, 0.05, 0.01])  # learning rates, which are considered during tuning stage\n",
    "momentum = 0.9  # momentum for optimizer, default 0\n",
    "weight_decay = 0  # weight_decay for optimizer, default 0\n",
    "\n",
    "exp_name = dataset + '_' + model  # experiment name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose compression operator\n",
    "\n",
    "Choose the one from the list. Compression is applied, when each node communicates with master. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression = {'wrapper': False, 'compression': None}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Natural Compression: [paper](https://arxiv.org/pdf/1905.10988.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression = {'wrapper': False, 'compression': c_nat} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Natural/Standard Dithering: [paper](https://arxiv.org/pdf/1905.10988.pdf)\n",
    "     - `'p'`: norm\n",
    "     - `'s'`: number of levels\n",
    "     - `'natural'`: if `True` then Natural Dithering else Standard dithering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression = {'wrapper': True, 'compression': random_dithering_wrap, 'p': np.inf, 's': 1, 'natural': True} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient Sparsification: [paper](https://papers.nips.cc/paper/7405-gradient-sparsification-for-communication-efficient-distributed-optimization.pdf)\n",
    "     - `'h'`: sparsity, $h \\in [0,1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression = {'wrapper': True, 'compression': grad_spars_wrap, 'h': 1/20} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Top-K Sparsification: \n",
    "     - `'h'`: sparsity, $h \\in [0,1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression = {'wrapper': True, 'compression': top_k_wrap, 'h': 1/20}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Sparsification: \n",
    "     - `'h'`: sparsity, $h \\in [0,1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression = {'wrapper': True, 'compression': rand_spars_wrap, 'h': 1/20} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Combination of two compression operators: \n",
    "     - `'comp1'`: compression operator applied to original vector\n",
    "     - `'comp2'`: (should be unbiased) if `'func'` is `biased_unbiased_wrap` then compression operator is applied to error \n",
    "     `e = g - comp1(g)` and the resulting compression returns `comp1(g) + comp2(e)`, if `'func'` is `combine_two_wrap`, then the \n",
    "     resulting compression returns `comp1(comp2(g))`\n",
    "     - Example of combination of Top-K and Gradient Sparsification below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression = {'combine': {\n",
    "    'func': biased_unbiased_wrap, \n",
    "    'comp_1': {'wrapper': True, 'compression': top_k_wrap, 'h': 1/40},\n",
    "    'comp_2': {'wrapper': True, 'compression': grad_spars_wrap, 'h': 1/40}\n",
    "    }\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to add, compression from master to nodes, then change default `master_compression = None` to any compression mentioned above. This compression does not have option for Error Feedback, thus unbiased compression should be selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_compression = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Feedback\n",
    "If `True`, Error feedback is used.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_feedback = True "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = exp_name + '_unique_identifier'  # name based on which your experiment will be stored\n",
    "exp = create_exp(name, dataset, net, n_workers, epochs, seed, batch_size, lrs,\n",
    "                 compression, error_feedback, criterion, master_compression, momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Step Size and Save Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp['lr'] = tune_step_size(exp)\n",
    "save_exp(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Experiment with tuned Step Size\n",
    "Each experiment is run `RUNS = 5` times. This value can be adjusted in [optim/train.py](optim/train.py) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_tuned_exp(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare methods -- Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_1 = load_exp(exp_name + '_identifier_1')\n",
    "exp_2 = load_exp(exp_name + '_identifier_2')\n",
    "exp_3 = load_exp(exp_name + '_identifier_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kind = 'test_acc'  # options: 'train_loss', 'test_loss', 'test_acc' \n",
    "exp_type = 'experiment_identifier'\n",
    "plot([exp_1, exp_2, exp_3], kind, log_scale=False,\n",
    "     legend=['Exp_1_Name', 'Exp_2_Name', 'Exp_1_Name'],\n",
    "     y_label='Test accuracy', file='File_To_Store_Plot.pdf')"
   ]
  },
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
